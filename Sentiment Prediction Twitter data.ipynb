{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import keras\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('sentiment/Sentiment.csv')\n",
    "data = data[['text','sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @NancyLeeGrahn: How did everyone feel about...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @ScottWalker: Didn't catch the full #GOPdeb...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @TJMShow: No mention of Tamir Rice and the ...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @RobGeorge: That Carly Fiorina is trending ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @DanScavino: #GOPDebate w/ @realDonaldTrump...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment\n",
       "0  RT @NancyLeeGrahn: How did everyone feel about...   Neutral\n",
       "1  RT @ScottWalker: Didn't catch the full #GOPdeb...  Positive\n",
       "2  RT @TJMShow: No mention of Tamir Rice and the ...   Neutral\n",
       "3  RT @RobGeorge: That Carly Fiorina is trending ...  Positive\n",
       "4  RT @DanScavino: #GOPDebate w/ @realDonaldTrump...  Positive"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4472\n",
      "16986\n"
     ]
    }
   ],
   "source": [
    "data = data[data.sentiment != \"Neutral\"]\n",
    "data['text'] = data['text'].apply(lambda x: x.lower())\n",
    "data['text'] = data['text'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]','',x)))\n",
    "\n",
    "print(data[ data['sentiment'] == 'Positive'].size)\n",
    "print(data[ data['sentiment'] == 'Negative'].size)\n",
    "\n",
    "for idx,row in data.iterrows():\n",
    "    row[0] = row[0].replace('rt',' ')\n",
    "    \n",
    "max_fatures = 2000\n",
    "tokenizer = Tokenizer(num_words=max_fatures, split=' ')\n",
    "tokenizer.fit_on_texts(data['text'].values)\n",
    "X = tokenizer.texts_to_sequences(data['text'].values)\n",
    "X = pad_sequences(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10729, 28)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "         363,  122,    1,  703,    2,   39,   58,  237,   37,  210,    6,\n",
       "         174, 1761,   12, 1324, 1409,  743],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          16,  284,  252,    5,  821,  102,  167,   26,  136,    6,    1,\n",
       "         173,   12,    2,  233,  724,   17]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 128\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_fatures, embed_dim,input_length = X.shape[1]))\n",
    "model.add(Dropout(0.20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(keras.layers.recurrent.SimpleRNN(units = 100, activation='relu',use_bias=True))\n",
    "model.add(keras.layers.Dense(units=1000, input_dim = 2000, activation='sigmoid'))\n",
    "model.add(keras.layers.Dense(units=500, input_dim=1000, activation='relu'))\n",
    "model.add(keras.layers.Dense(units=2, input_dim=500,activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7188, 28) (7188, 2)\n",
      "(3541, 28) (3541, 2)\n"
     ]
    }
   ],
   "source": [
    "Y = pd.get_dummies(data['sentiment']).values\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.33, random_state = 42)\n",
    "print(X_train.shape,Y_train.shape)\n",
    "print(X_test.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ZekeLabs\\Anaconda3-N\\lib\\site-packages\\keras\\models.py:939: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/17\n",
      " - 23s - loss: 0.5318 - acc: 0.7924\n",
      "Epoch 2/17\n",
      " - 17s - loss: 0.3423 - acc: 0.8582\n",
      "Epoch 3/17\n",
      " - 17s - loss: 0.2440 - acc: 0.9060\n",
      "Epoch 4/17\n",
      " - 17s - loss: 0.1752 - acc: 0.9350\n",
      "Epoch 5/17\n",
      " - 17s - loss: 0.1627 - acc: 0.9393\n",
      "Epoch 6/17\n",
      " - 17s - loss: 0.1246 - acc: 0.9540\n",
      "Epoch 7/17\n",
      " - 17s - loss: 0.0987 - acc: 0.9626\n",
      "Epoch 8/17\n",
      " - 17s - loss: 0.0953 - acc: 0.9634\n",
      "Epoch 9/17\n",
      " - 17s - loss: 0.0866 - acc: 0.9655\n",
      "Epoch 10/17\n",
      " - 17s - loss: 0.0858 - acc: 0.9665\n",
      "Epoch 11/17\n",
      " - 17s - loss: 0.0765 - acc: 0.9687\n",
      "Epoch 12/17\n",
      " - 17s - loss: 0.0729 - acc: 0.9681\n",
      "Epoch 13/17\n",
      " - 17s - loss: 0.0793 - acc: 0.9683\n",
      "Epoch 14/17\n",
      " - 18s - loss: 0.0753 - acc: 0.9697\n",
      "Epoch 15/17\n",
      " - 17s - loss: 0.0708 - acc: 0.9711\n",
      "Epoch 16/17\n",
      " - 17s - loss: 0.0673 - acc: 0.9702\n",
      "Epoch 17/17\n",
      " - 17s - loss: 0.0802 - acc: 0.9687\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23635391b70>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "model.fit(X_train, Y_train, nb_epoch = 17, batch_size=batch_size, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  9.21380162e-01,   7.86197856e-02],\n",
       "       [  9.87706840e-01,   1.22931534e-02],\n",
       "       [  8.12505722e-01,   1.87494248e-01],\n",
       "       [  9.98835862e-01,   1.16410200e-03],\n",
       "       [  9.97321069e-01,   2.67897709e-03],\n",
       "       [  8.84306431e-02,   9.11569417e-01],\n",
       "       [  9.99960661e-01,   3.93490773e-05],\n",
       "       [  9.99059260e-01,   9.40774451e-04],\n",
       "       [  5.32969832e-01,   4.67030227e-01],\n",
       "       [  9.98835266e-01,   1.16479525e-03]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 28, 128)           256000    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 28, 128)           0         \n",
      "_________________________________________________________________\n",
      "simple_rnn_1 (SimpleRNN)     (None, 100)               22900     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1000)              101000    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 500)               500500    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 1002      \n",
      "=================================================================\n",
      "Total params: 881,402\n",
      "Trainable params: 881,402\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_fatures, embed_dim,input_length = X.shape[1]))\n",
    "model.add(Dropout(0.20))\n",
    "model.add(LSTM(64, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, 28, 128)           256000    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 28, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 64)                49408     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 305,538\n",
      "Trainable params: 305,538\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      " - 43s - loss: 0.4393 - acc: 0.8141\n",
      "Epoch 2/7\n",
      " - 46s - loss: 0.3156 - acc: 0.8699\n",
      "Epoch 3/7\n",
      " - 41s - loss: 0.2710 - acc: 0.8900\n",
      "Epoch 4/7\n",
      " - 40s - loss: 0.2401 - acc: 0.9033\n",
      "Epoch 5/7\n",
      " - 32s - loss: 0.2169 - acc: 0.9144\n",
      "Epoch 6/7\n",
      " - 31s - loss: 0.1914 - acc: 0.9229\n",
      "Epoch 7/7\n",
      " - 32s - loss: 0.1731 - acc: 0.9285\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x236389c98d0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, epochs = 7, batch_size=batch_size, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'class_name': 'Embedding',\n",
       "  'config': {'activity_regularizer': None,\n",
       "   'batch_input_shape': (None, 28),\n",
       "   'dtype': 'float32',\n",
       "   'embeddings_constraint': None,\n",
       "   'embeddings_initializer': {'class_name': 'RandomUniform',\n",
       "    'config': {'maxval': 0.05, 'minval': -0.05, 'seed': None}},\n",
       "   'embeddings_regularizer': None,\n",
       "   'input_dim': 2000,\n",
       "   'input_length': 28,\n",
       "   'mask_zero': False,\n",
       "   'name': 'embedding_7',\n",
       "   'output_dim': 128,\n",
       "   'trainable': True}},\n",
       " {'class_name': 'Dropout',\n",
       "  'config': {'name': 'dropout_4',\n",
       "   'noise_shape': None,\n",
       "   'rate': 0.2,\n",
       "   'seed': None,\n",
       "   'trainable': True}},\n",
       " {'class_name': 'LSTM',\n",
       "  'config': {'activation': 'tanh',\n",
       "   'activity_regularizer': None,\n",
       "   'bias_constraint': None,\n",
       "   'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "   'bias_regularizer': None,\n",
       "   'dropout': 0.2,\n",
       "   'go_backwards': False,\n",
       "   'implementation': 1,\n",
       "   'kernel_constraint': None,\n",
       "   'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "    'config': {'distribution': 'uniform',\n",
       "     'mode': 'fan_avg',\n",
       "     'scale': 1.0,\n",
       "     'seed': None}},\n",
       "   'kernel_regularizer': None,\n",
       "   'name': 'lstm_2',\n",
       "   'recurrent_activation': 'hard_sigmoid',\n",
       "   'recurrent_constraint': None,\n",
       "   'recurrent_dropout': 0.2,\n",
       "   'recurrent_initializer': {'class_name': 'Orthogonal',\n",
       "    'config': {'gain': 1.0, 'seed': None}},\n",
       "   'recurrent_regularizer': None,\n",
       "   'return_sequences': False,\n",
       "   'return_state': False,\n",
       "   'stateful': False,\n",
       "   'trainable': True,\n",
       "   'unit_forget_bias': True,\n",
       "   'units': 64,\n",
       "   'unroll': False,\n",
       "   'use_bias': True}},\n",
       " {'class_name': 'Dense',\n",
       "  'config': {'activation': 'softmax',\n",
       "   'activity_regularizer': None,\n",
       "   'bias_constraint': None,\n",
       "   'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "   'bias_regularizer': None,\n",
       "   'kernel_constraint': None,\n",
       "   'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "    'config': {'distribution': 'uniform',\n",
       "     'mode': 'fan_avg',\n",
       "     'scale': 1.0,\n",
       "     'seed': None}},\n",
       "   'kernel_regularizer': None,\n",
       "   'name': 'dense_8',\n",
       "   'trainable': True,\n",
       "   'units': 2,\n",
       "   'use_bias': True}}]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       ..., \n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1]], dtype=uint8)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1        Positive\n",
       "3        Positive\n",
       "4        Positive\n",
       "5        Positive\n",
       "6        Negative\n",
       "8        Negative\n",
       "9        Negative\n",
       "10       Negative\n",
       "11       Positive\n",
       "12       Negative\n",
       "14       Positive\n",
       "15       Negative\n",
       "16       Negative\n",
       "17       Negative\n",
       "18       Negative\n",
       "19       Negative\n",
       "20       Positive\n",
       "21       Negative\n",
       "22       Negative\n",
       "24       Negative\n",
       "25       Negative\n",
       "26       Negative\n",
       "27       Negative\n",
       "28       Negative\n",
       "29       Negative\n",
       "30       Negative\n",
       "31       Negative\n",
       "34       Negative\n",
       "35       Negative\n",
       "36       Negative\n",
       "           ...   \n",
       "13839    Negative\n",
       "13840    Negative\n",
       "13841    Negative\n",
       "13843    Negative\n",
       "13844    Negative\n",
       "13845    Negative\n",
       "13847    Positive\n",
       "13848    Negative\n",
       "13849    Positive\n",
       "13850    Negative\n",
       "13851    Negative\n",
       "13852    Negative\n",
       "13853    Negative\n",
       "13854    Negative\n",
       "13855    Negative\n",
       "13856    Negative\n",
       "13857    Negative\n",
       "13858    Positive\n",
       "13859    Positive\n",
       "13860    Negative\n",
       "13861    Negative\n",
       "13862    Positive\n",
       "13863    Negative\n",
       "13864    Negative\n",
       "13865    Negative\n",
       "13866    Negative\n",
       "13867    Positive\n",
       "13868    Positive\n",
       "13869    Negative\n",
       "13870    Positive\n",
       "Name: sentiment, Length: 10729, dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       ..., \n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3541/3541 [==============================] - 6s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.43480763399846739, 0.83168596445049681]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       ..., \n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1]], dtype=uint8)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
